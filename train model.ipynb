{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.745074</td>\n",
       "      <td>12.745074</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>-3.844312</td>\n",
       "      <td>0.674260</td>\n",
       "      <td>386.429</td>\n",
       "      <td>368.285</td>\n",
       "      <td>386.093643</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.042165</td>\n",
       "      <td>13.042165</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>-0.983744</td>\n",
       "      <td>0.161820</td>\n",
       "      <td>587.798</td>\n",
       "      <td>534.374</td>\n",
       "      <td>587.382203</td>\n",
       "      <td>236</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.950279</td>\n",
       "      <td>11.950279</td>\n",
       "      <td>0.039957</td>\n",
       "      <td>-1.135544</td>\n",
       "      <td>0.324593</td>\n",
       "      <td>358.460</td>\n",
       "      <td>332.252</td>\n",
       "      <td>358.156243</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.065296</td>\n",
       "      <td>4.065296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848193</td>\n",
       "      <td>236.746</td>\n",
       "      <td>219.610</td>\n",
       "      <td>236.108026</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12.701627</td>\n",
       "      <td>12.701627</td>\n",
       "      <td>0.028753</td>\n",
       "      <td>-1.339216</td>\n",
       "      <td>0.171662</td>\n",
       "      <td>451.442</td>\n",
       "      <td>438.338</td>\n",
       "      <td>451.025640</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  \\\n",
       "0           0          12.745074       12.745074           0.116445   \n",
       "1           1          13.042165       13.042165           0.099477   \n",
       "2           2          11.950279       11.950279           0.039957   \n",
       "3           3           4.065296        4.065296           0.000000   \n",
       "4           4          12.701627       12.701627           0.028753   \n",
       "\n",
       "   MinEStateIndex       qed    MolWt  HeavyAtomMolWt  ExactMolWt  \\\n",
       "0       -3.844312  0.674260  386.429         368.285  386.093643   \n",
       "1       -0.983744  0.161820  587.798         534.374  587.382203   \n",
       "2       -1.135544  0.324593  358.460         332.252  358.156243   \n",
       "3        0.000000  0.848193  236.746         219.610  236.108026   \n",
       "4       -1.339216  0.171662  451.442         438.338  451.025640   \n",
       "\n",
       "   NumValenceElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0                  140  ...           0             1           0   \n",
       "1                  236  ...           0             0           0   \n",
       "2                  136  ...           1             0           0   \n",
       "3                   86  ...           0             0           0   \n",
       "4                  156  ...           1             0           0   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiophene  \\\n",
       "0                  0             0            0             0   \n",
       "1                  0             0            0             0   \n",
       "2                  0             0            0             0   \n",
       "3                  0             0            0             0   \n",
       "4                  1             0            1             0   \n",
       "\n",
       "   fr_unbrch_alkane  fr_urea  Activity  \n",
       "0                 0        0         0  \n",
       "1                 0        0         1  \n",
       "2                 4        0         1  \n",
       "3                 0        0         0  \n",
       "4                 0        0         1  \n",
       "\n",
       "[5 rows x 205 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "data = pd.read_excel(\"final_data_used_1.xlsx\")\n",
    "\n",
    "# View the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>NumRadicalElectrons</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.745074</td>\n",
       "      <td>12.745074</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>-3.844312</td>\n",
       "      <td>0.674260</td>\n",
       "      <td>386.429</td>\n",
       "      <td>368.285</td>\n",
       "      <td>386.093643</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.042165</td>\n",
       "      <td>13.042165</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>-0.983744</td>\n",
       "      <td>0.161820</td>\n",
       "      <td>587.798</td>\n",
       "      <td>534.374</td>\n",
       "      <td>587.382203</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.950279</td>\n",
       "      <td>11.950279</td>\n",
       "      <td>0.039957</td>\n",
       "      <td>-1.135544</td>\n",
       "      <td>0.324593</td>\n",
       "      <td>358.460</td>\n",
       "      <td>332.252</td>\n",
       "      <td>358.156243</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.065296</td>\n",
       "      <td>4.065296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848193</td>\n",
       "      <td>236.746</td>\n",
       "      <td>219.610</td>\n",
       "      <td>236.108026</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.701627</td>\n",
       "      <td>12.701627</td>\n",
       "      <td>0.028753</td>\n",
       "      <td>-1.339216</td>\n",
       "      <td>0.171662</td>\n",
       "      <td>451.442</td>\n",
       "      <td>438.338</td>\n",
       "      <td>451.025640</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  \\\n",
       "0          12.745074       12.745074           0.116445       -3.844312   \n",
       "1          13.042165       13.042165           0.099477       -0.983744   \n",
       "2          11.950279       11.950279           0.039957       -1.135544   \n",
       "3           4.065296        4.065296           0.000000        0.000000   \n",
       "4          12.701627       12.701627           0.028753       -1.339216   \n",
       "\n",
       "        qed    MolWt  HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  \\\n",
       "0  0.674260  386.429         368.285  386.093643                  140   \n",
       "1  0.161820  587.798         534.374  587.382203                  236   \n",
       "2  0.324593  358.460         332.252  358.156243                  136   \n",
       "3  0.848193  236.746         219.610  236.108026                   86   \n",
       "4  0.171662  451.442         438.338  451.025640                  156   \n",
       "\n",
       "   NumRadicalElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0                    0  ...           0             1           0   \n",
       "1                    0  ...           0             0           0   \n",
       "2                    0  ...           1             0           0   \n",
       "3                    0  ...           0             0           0   \n",
       "4                    0  ...           1             0           0   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiophene  \\\n",
       "0                  0             0            0             0   \n",
       "1                  0             0            0             0   \n",
       "2                  0             0            0             0   \n",
       "3                  0             0            0             0   \n",
       "4                  1             0            1             0   \n",
       "\n",
       "   fr_unbrch_alkane  fr_urea  Activity  \n",
       "0                 0        0         0  \n",
       "1                 0        0         1  \n",
       "2                 4        0         1  \n",
       "3                 0        0         0  \n",
       "4                 0        0         1  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Unnamed: 0'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('train_test_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxAbsEStateIndex    0\n",
       "MaxEStateIndex       0\n",
       "MinAbsEStateIndex    0\n",
       "MinEStateIndex       0\n",
       "qed                  0\n",
       "                    ..\n",
       "fr_thiazole          0\n",
       "fr_thiophene         0\n",
       "fr_unbrch_alkane     0\n",
       "fr_urea              0\n",
       "Activity             0\n",
       "Length: 204, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 'NaN' values in the DataFrame.\n",
      "Rows with 'NaN' values:\n",
      "      MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  \\\n",
      "28            12.136282       12.136282                0.0       -3.993201   \n",
      "30             4.338333        4.338333                0.0       -0.363333   \n",
      "60            10.848145       10.848145                0.0       -1.494225   \n",
      "73            10.148889       10.148889                0.0       -2.974537   \n",
      "133           11.244742       11.244742                0.0       -4.628815   \n",
      "...                 ...             ...                ...             ...   \n",
      "4508          11.360956       11.360956                0.0       -4.372897   \n",
      "4540          10.403473       10.403473                0.0       -1.529998   \n",
      "4554          10.514585       10.514585                0.0       -1.517652   \n",
      "4591          11.755694       11.755694                0.0       -1.150139   \n",
      "4601          10.928526       10.928526                0.0       -0.840869   \n",
      "\n",
      "           qed    MolWt  HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  \\\n",
      "28    0.610983  392.412         375.276  392.080672                  134   \n",
      "30    0.394078  262.302         252.222  263.878091                   50   \n",
      "60    0.170138  500.381         479.213  500.052947                  154   \n",
      "73    0.455519  398.079         393.039  397.983926                   76   \n",
      "133   0.189677  514.452         502.356  513.999365                  162   \n",
      "...        ...      ...             ...         ...                  ...   \n",
      "4508  0.280570  493.478         479.366  493.024697                  162   \n",
      "4540  0.308256  391.836         379.740  390.952651                  125   \n",
      "4554  0.356269  345.065         331.961  345.002128                  119   \n",
      "4591  0.412391  234.231         219.111  234.098037                   84   \n",
      "4601  0.875313  282.352         268.240  282.056885                   94   \n",
      "\n",
      "      NumRadicalElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
      "28                      0  ...           0             1           0   \n",
      "30                      0  ...           0             0           0   \n",
      "60                      0  ...           0             0           0   \n",
      "73                      2  ...           0             0           0   \n",
      "133                     0  ...           0             0           0   \n",
      "...                   ...  ...         ...           ...         ...   \n",
      "4508                    0  ...           0             0           0   \n",
      "4540                    1  ...           0             0           0   \n",
      "4554                    1  ...           0             0           0   \n",
      "4591                    0  ...           0             0           0   \n",
      "4601                    2  ...           0             0           0   \n",
      "\n",
      "      fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiophene  \\\n",
      "28                    0             0            0             0   \n",
      "30                    0             0            0             0   \n",
      "60                    0             0            0             0   \n",
      "73                    0             0            0             0   \n",
      "133                   0             0            0             0   \n",
      "...                 ...           ...          ...           ...   \n",
      "4508                  0             0            0             0   \n",
      "4540                  0             0            0             0   \n",
      "4554                  0             0            0             0   \n",
      "4591                  0             0            0             0   \n",
      "4601                  0             0            0             0   \n",
      "\n",
      "      fr_unbrch_alkane  fr_urea  Activity  \n",
      "28                   0        0         0  \n",
      "30                   0        0         0  \n",
      "60                   0        0         0  \n",
      "73                   0        0         0  \n",
      "133                  0        0         0  \n",
      "...                ...      ...       ...  \n",
      "4508                 0        0         0  \n",
      "4540                 0        0         0  \n",
      "4554                 0        0         0  \n",
      "4591                 0        0         0  \n",
      "4601                 0        0         0  \n",
      "\n",
      "[226 rows x 204 columns]\n",
      "Columns with 'NaN' values:\n",
      "['MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_dataframe' with the name of your actual DataFrame\n",
    "# Check for 'NaN' values in the entire DataFrame\n",
    "nan_values = data.isna().sum()\n",
    "\n",
    "# Check if any 'NaN' values exist\n",
    "if nan_values.any():\n",
    "    print(\"There are 'NaN' values in the DataFrame.\")\n",
    "\n",
    "# To specifically identify rows or columns containing NaN values:\n",
    "# Check for 'NaN' values in specific rows or columns\n",
    "nan_rows = data[data.isna().any(axis=1)]\n",
    "nan_columns = data.columns[data.isna().any()].tolist()\n",
    "\n",
    "# Display rows with NaN values\n",
    "if not nan_rows.empty:\n",
    "    print(\"Rows with 'NaN' values:\")\n",
    "    print(nan_rows)\n",
    "\n",
    "# Display columns with NaN values\n",
    "if nan_columns:\n",
    "    print(\"Columns with 'NaN' values:\")\n",
    "    print(nan_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\extmath.py:1066: RuntimeWarning: overflow encountered in square\n",
      "  temp **= 2\n",
      "c:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\extmath.py:1072: RuntimeWarning: overflow encountered in square\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "c:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\extmath.py:1072: RuntimeWarning: invalid value encountered in subtract\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "c:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:86: RuntimeWarning: overflow encountered in square\n",
      "  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\senior project\\Dataset\\train model.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/Dataset/train%20model.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m rf_classifier \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/Dataset/train%20model.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Train the model on the training set\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/senior%20project/Dataset/train%20model.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m rf_classifier\u001b[39m.\u001b[39;49mfit(X_train_scaled, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/Dataset/train%20model.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Make predictions on the testing set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/Dataset/train%20model.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m y_pred \u001b[39m=\u001b[39m rf_classifier\u001b[39m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32mc:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    346\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    348\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\chon7\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace 'your_feature_columns' with the actual names of your feature columns\n",
    "X = data.drop(['Activity'], axis=1)\n",
    "# Replace 'your_label_column' with the actual name of your label column\n",
    "y = data['Activity']\n",
    "\n",
    "# Impute missing values in the original data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Split the standardized data into training and testing sets\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a new dataframe 'new_data' with the same features as your training data\n",
    "# Replace 'your_feature_column_1', 'your_feature_column_2', ... with the actual names of your feature columns\n",
    "new_X = new_data[['your_feature_column_1', 'your_feature_column_2', ...]]\n",
    "\n",
    "# Use the trained Random Forest Classifier to make predictions on the new data\n",
    "new_predictions = rf_classifier.predict(new_X)\n",
    "\n",
    "# Print the predicted labels for the new data\n",
    "print(\"Predicted Labels for New Data:\")\n",
    "print(new_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive baysian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "data_1 = pd.read_excel(\"train_test_data.xlsx\")\n",
    "\n",
    "# View the first 5 rows\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Extract features and target variable\n",
    "X = data_1[['mw', 'xlogp', 'polararea','hbondacc','hbonddonor','rotbonds','heavycnt']]\n",
    "y = data_1['Activity']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessing_pipeline = make_pipeline(\n",
    "    StandardScaler()  # Standardize the features\n",
    ")\n",
    "\n",
    "# Fit and transform the preprocessing pipeline on the training data\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same preprocessing pipeline\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "# Create a Gaussian Naive Bayes Classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the model on the preprocessed training set\n",
    "nb_classifier.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Make predictions on the preprocessed testing set\n",
    "y_pred = nb_classifier.predict(X_test_preprocessed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "data_1 = pd.read_excel(\"final_data_used_1.xlsx\")\n",
    "\n",
    "# View the first 5 rows\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data.drop(['Unnamed: 0'], axis=1)\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Replace 'your_feature_columns' with the actual names of your feature columns\n",
    "X = data_1.drop(['Activity'], axis=1)\n",
    "# Replace 'your_label_column' with the actual name of your label column\n",
    "y = data_1['Activity']\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the standardized data into training and testing sets\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the model on the standardized training set\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the standardized testing set\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Replace 'your_feature_columns' with the actual names of your feature columns\n",
    "X = data_2[['mw', 'xlogp', 'polararea', 'hbondacc', 'hbonddonor', 'rotbonds', 'heavycnt']]\n",
    "# Replace 'your_label_column' with the actual name of your label column\n",
    "y = data_2['Activity']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define columns by their types: numerical and categorical\n",
    "numerical_features = ['mw', 'xlogp', 'polararea', 'hbondacc', 'hbonddonor', 'rotbonds', 'heavycnt']\n",
    "categorical_features = []  # Assuming there are no categorical features in this case\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # Scale the numerical features\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data (empty for this example)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Placeholder for categorical handling\n",
    "])\n",
    "\n",
    "# Combine preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a preprocessing and modeling pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC())  # SVM classifier\n",
    "])\n",
    "\n",
    "# Train the model (including preprocessing) on the training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold cross validation svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "data_3 = pd.read_excel(\"train_test_data.xlsx\")\n",
    "\n",
    "# View the first 5 rows\n",
    "data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = data_3.drop('Unnamed: 0', axis=1)\n",
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming 'df' is your DataFrame with features and target variable\n",
    "\n",
    "# Extract features and target variable\n",
    "X = data_3.drop('Activity', axis=1)  # Replace 'target_column' with the actual name of your target column\n",
    "y = data_3['Activity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM model with a pipeline including standardization\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k_folds = 10  # You can adjust the number of folds as needed\n",
    "cv_scores = cross_val_score(svm_model, X_train, y_train, cv=k_folds)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "print(f'Mean CV Score: {cv_scores.mean()}')\n",
    "\n",
    "# Fit the model on the entire training set\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = svm_model.score(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
